{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546b06a5-a4ce-4c83-859f-c154bc2a6356",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=L9TfZdODuFQ\n",
    "- https://algomaster.io/learn/lld/design-tic-tac-toe\n",
    "- https://algomaster.io/learn/system-design/client-server-architecture\n",
    "\n",
    "https://www.youtube.com/watch?v=s9Qh9fWeOAk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23a4016-b11a-463d-af9e-fbefad143b67",
   "metadata": {},
   "source": [
    "1. *Define the Problem Space:*\n",
    " - Understand problem and define scope.\n",
    " - Clarify functional and non-functional requirements.\n",
    " - State assumptions and decisions explicitly.\n",
    "\n",
    "2. *Design the System at a High Level:*\n",
    " - Design APIs to define how clients access system resources.\n",
    " - Consider request parameters, response types, and communication between client and server.\n",
    " - Create a high-level design diagram to illustrate system architecture.\n",
    "\n",
    "3. *Deep Dive into the Design:*\n",
    " - Examine system components and relationships in detail.\n",
    " - Consider non-functional requirements' impact on design choices.\n",
    " - Present different design options with pros and cons.\n",
    "\n",
    "4. *Identify Bottlenecks and Scaling Opportunities:*\n",
    " - Assess system's ability to operate under various conditions and support growth.\n",
    " - Address single points of failure, data replication, global service support, and scalability.\n",
    " - Consider concepts like horizontal sharding, CDN, caching, rate limiting, and databases.\n",
    "\n",
    "5. *Review and Wrap Up:*\n",
    " - Summarize major decisions with justifications and trade-offs.\n",
    " - Ensure design satisfies all requirements.\n",
    " - Identify directions for further improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cb634d-d57d-417e-9459-7b367adb284a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bd8dd7a-649f-4a2f-a3cd-9bc6168adbe0",
   "metadata": {},
   "source": [
    "Of course. Here is a complete, structured guide on how to answer system design interview questions, from the initial approach to a full example walkthrough.\n",
    "\n",
    "The Ultimate Guide to Acing System Design Interviews\n",
    "System design interviews assess your ability to architect a complex, scalable, and reliable system. It's not about finding the \"right\" answer, but about demonstrating your thought process, prioritization, and engineering judgment.\n",
    "\n",
    "Part 1: The Mindset & Core Principles\n",
    "Before you start, internalize these principles:\n",
    "\n",
    "It's a Dialogue, Not a Monologue: Engage the interviewer. Ask clarifying questions. Treat them as a collaborative partner.\n",
    "\n",
    "There is No Perfect Answer: The goal is to design a reasonable system that meets the requirements. Be prepared to discuss trade-offs.\n",
    "\n",
    "Start Simple, Then Scale: Begin with a basic, naive solution. Then, identify bottlenecks and iteratively improve the design. This shows your problem-solving skills.\n",
    "\n",
    "Communication is Key: Explain your reasoning. Use a whiteboard (virtual or physical) to draw diagrams. A picture is worth a thousand words.\n",
    "\n",
    "Part 2: The Step-by-Step Framework (The Blueprint)\n",
    "Follow this structured framework to tackle any system design question. Memorize these steps.\n",
    "\n",
    "Step 1: Clarify Requirements and Define Scope (5-10 mins)\n",
    "Don't jump into solutions! First, ensure you understand the problem.\n",
    "\n",
    "Ask \"What\" and \"Why\":\n",
    "\n",
    "What are we building? (e.g., \"Is this a read-heavy or write-heavy system?\")\n",
    "\n",
    "Who are the users? (e.g., \"Is this for end-users or a backend service?\")\n",
    "\n",
    "What is the scale? Ask about:\n",
    "\n",
    "DAU (Daily Active Users): To understand user base.\n",
    "\n",
    "Read/Write QPS (Queries Per Second): To understand traffic patterns.\n",
    "\n",
    "Data Storage Size: (e.g., \"How many new posts per day? Average post size?\").\n",
    "\n",
    "Define Functional Requirements (Features):\n",
    "\n",
    "What are the core features? (e.g., For Twitter: Post a tweet, view a timeline, follow a user).\n",
    "\n",
    "Define Non-Functional Requirements (The \"-ilities\"):\n",
    "\n",
    "Scalability: Can it handle growth?\n",
    "\n",
    "Reliability/Availability: Is it always up? (Measured in \"nines,\" e.g., 99.9%).\n",
    "\n",
    "Latency: How fast does it need to be? (e.g., API response time < 200ms).\n",
    "\n",
    "Consistency: Strong or eventual consistency?\n",
    "\n",
    "Durability: Is data never lost?\n",
    "\n",
    "Example: For \"Design Twitter,\" you might clarify: \"Are we focusing on the tweet feed, or do we also need to design direct messaging and search?\"\n",
    "\n",
    "Step 2: High-Level System Design (5-10 mins)\n",
    "Sketch the backbone of your system. Identify the main components and how data flows.\n",
    "\n",
    "Draw a Client-Server Diagram:\n",
    "\n",
    "Clients (Web, Mobile) → Load Balancer → Application Servers (API Layer) → Various Backend Services → Databases/Caches.\n",
    "\n",
    "API Definitions:\n",
    "\n",
    "Briefly define the key endpoints, their methods, and parameters.\n",
    "\n",
    "Example: postTweet(user_id, tweet_content, auth_token)\n",
    "\n",
    "Step 3: Deep Dive into Core Components\n",
    "This is the main part of the interview. Go through each layer, justifying your technology choices.\n",
    "\n",
    "A. Data Model & Database Selection\n",
    "\n",
    "Relational (SQL - MySQL, PostgreSQL): Good for complex queries, transactions, and strong consistency. Use for user data, financial data.\n",
    "\n",
    "NoSQL:\n",
    "\n",
    "Key-Value (Redis, DynamoDB): Great for caching, session storage. Very fast.\n",
    "\n",
    "Document (MongoDB): Good for flexible, hierarchical data.\n",
    "\n",
    "Wide-Column (Cassandra, HBase): Excellent for massive write throughput and scalability.\n",
    "\n",
    "Graph (Neo4j): Ideal for social networks (followers) and recommendation engines.\n",
    "\n",
    "Decision: \"We'll use a SQL database for user accounts to ensure ACID properties, and a NoSQL wide-column store for tweets because of its high write scalability.\"\n",
    "\n",
    "B. Application Logic & Microservices (Optional but Good)\n",
    "\n",
    "Break down the system into logical services (e.g., User Service, Tweet Service, Timeline Service, Notification Service).\n",
    "\n",
    "Discuss how they communicate (e.g., synchronous REST/GRPC, asynchronous message queues).\n",
    "\n",
    "C. Storage & Caching\n",
    "\n",
    "Caching is crucial for performance. Use it for frequently accessed, read-heavy data.\n",
    "\n",
    "Where to cache?\n",
    "\n",
    "CDN (CloudFront, Akamai): For static assets (images, JS, CSS).\n",
    "\n",
    "Application Cache (Redis, Memcached): For database query results, session data (e.g., a user's profile).\n",
    "\n",
    "Cache Strategy: Discuss Cache-Aside (Lazy Loading) or Write-Through.\n",
    "\n",
    "D. Load Balancing & Horizontal Scaling\n",
    "\n",
    "Explain how you'll distribute traffic across multiple servers using a Load Balancer (e.g., AWS ELB/ALB, Nginx).\n",
    "\n",
    "Step 4: Identify and Address Bottlenecks & Scale\n",
    "This is where you show your expertise. Go back to your HLD and ask, \"What will break under load?\"\n",
    "\n",
    "Single Point of Failure (SPOF): \"Our single database is a SPOF. We'll add read replicas and implement failover.\"\n",
    "\n",
    "Database Write Scalability: \"If we get 10,000 tweets per second, our database will struggle. We might need to shard/partition the tweets table by user_id or tweet_id.\"\n",
    "\n",
    "Timeline Generation: \"Generating a home timeline for a user with millions of followers on-the-fly is too slow. We'll use a Fan-out approach: pre-compute timelines and store them in a cache.\"\n",
    "\n",
    "Network Latency: \"Users in Asia will have high latency to our US data center. We'll use a multi-region setup with geo-DNS.\"\n",
    "\n",
    "Step 5: Advanced Topics & Trade-offs (If Time Permits)\n",
    "Consistency vs. Availability (CAP Theorem): \"For the tweet service, we favor availability over strong consistency. It's okay if a tweet takes a few seconds to appear everywhere (eventual consistency).\"\n",
    "\n",
    "Message Queues (Kafka, RabbitMQ, SQS): For decoupling services and handling asynchronous tasks (e.g., sending notifications, processing images).\n",
    "\n",
    "Monitoring & Observability: How will you know the system is healthy? (Logging, Metrics, Tracing).\n",
    "\n",
    "Security: Discuss API authentication (OAuth, JWT), HTTPS, and SQL injection prevention.\n",
    "\n",
    "Part 3: A Concrete Example: \"Design a URL Shortener like TinyURL\"\n",
    "Let's apply the framework.\n",
    "\n",
    "Step 1: Clarify Requirements\n",
    "\n",
    "Functional: Shorten a long URL. Redirect short URL to long URL.\n",
    "\n",
    "Non-Functional: High availability, low latency (for redirects), scalable.\n",
    "\n",
    "Scale:\n",
    "\n",
    "100 million new URLs per month.\n",
    "\n",
    "Read-heavy (100:1 ratio of reads to writes). 10B redirects per month.\n",
    "\n",
    "QPS: ~400 writes/s, ~40,000 reads/s.\n",
    "\n",
    "Step 2: High-Level Design\n",
    "\n",
    "Client → LB → Web Servers → Encoding Service & Database.\n",
    "\n",
    "Step 3: Deep Dive\n",
    "\n",
    "API:\n",
    "\n",
    "createURL(api_key, long_url, custom_alias=None) -> short_url\n",
    "\n",
    "getURL(short_url) -> HTTP 302 Redirect to long_url\n",
    "\n",
    "Data Model:\n",
    "\n",
    "url_mappings table: short_code (PK, varchar), long_url (text), created_at, user_id, expires_at.\n",
    "\n",
    "Key Algorithm: How to generate the short code?\n",
    "\n",
    "Option 1: Hash (MD5/SHA) then base62 encode. Check for collisions.\n",
    "\n",
    "Option 2: Generate from a Global Sequence. A highly available service (like Twitter's Snowflake) generates unique, ever-increasing IDs, which are then base62 encoded. This is more scalable and avoids collisions.\n",
    "\n",
    "Database: A simple key-value store is perfect. short_code is the key, long_url is the value. We can use Redis for blazing fast reads and DynamoDB/Cassandra for persistent, scalable storage.\n",
    "\n",
    "Step 4: Scaling & Bottlenecks\n",
    "\n",
    "Bottleneck: The single database for generating unique keys.\n",
    "\n",
    "Solution: Use the Global Sequence (Snowflake) approach, which can generate millions of IDs per second across multiple machines.\n",
    "\n",
    "Bottleneck: Cache Miss Storm.\n",
    "\n",
    "Solution: Use a Cache-Aside pattern with Redis in front of the database. For popular URLs, this will serve 99% of requests.\n",
    "\n",
    "Step 5: Advanced Topics\n",
    "\n",
    "Trade-off: We chose eventual consistency for faster writes. A new URL might not be instantly available in all caches, but that's acceptable.\n",
    "\n",
    "Cleanup: Implement a TTL (Time-To-Live) on the cache and database entries for unused URLs.\n",
    "\n",
    "Security: Prevent abuse with API rate-limiting.\n",
    "\n",
    "Part 4: Final Tips for Success\n",
    "Practice, Practice, Practice: Use sites like bytebytego.com, educative.io, and interviewing.io to practice common questions (Chat, Social Feed, Search, File Storage).\n",
    "\n",
    "Stay Calm and Structured: If you get stuck, go back to the framework. It's your safety net.\n",
    "\n",
    "Be Honest: If you don't know something, say so, but try to reason about it. \"I'm not deeply familiar with Kafka, but I believe a message queue would be appropriate here to decouple the services...\" is a great answer.\n",
    "\n",
    "Ask Questions at the End: This shows genuine interest. \"How would your team have approached this differently?\"\n",
    "\n",
    "By following this guide, you will demonstrate a methodical, knowledgeable, and collaborative approach that interviewers are looking for. Good luck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc096c8-924f-4a5e-804a-c9f65904929e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
